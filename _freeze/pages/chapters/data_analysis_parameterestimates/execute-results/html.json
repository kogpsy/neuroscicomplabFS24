{
  "hash": "294eedc80cf2bed5bbbc2a41e58fb1fc",
  "result": {
    "markdown": "---\ntitle: \"Parameterschätzung\"\ndescription: \"Einführung in die Bayesianische Statistik\"\nauthor:\n  - name: Gerda Wyssen\n    affiliation: Kognitive Psychologie, Wahrnehmung und Methodenlehre, Universität Bern \n    affiliation-url: https://www.kog.psy.unibe.ch\n    orcid: 0000-0001-7427-3149\n  - name: Andrew Ellis\n    url: https://github.com/awellis\n    affiliation: Kognitive Psychologie, Wahrnehmung und Methodenlehre, Universität Bern \n    affiliation_url: https://www.kog.psy.unibe.ch\n    orcid: 0000-0002-2788-936X\n  - name: Daniel Fitze\n    affiliation: Kognitive Psychologie, Wahrnehmung und Methodenlehre, Universität Bern \n    affiliation-url: https://www.kog.psy.unibe.ch\n    orcid: 0000-0003-0158-7459  \nlicense: CC BY\ncitation: true\nbibliography: ../../bibliography_nsci24.bib\nformat:\n    html:\n        toc: true\n        code-link: true\n---\n\n\nNach dem Data Cleaning und Preprocessing geht es darum, welche Informationen die Daten über den zu untersuchenden Prozess beinhalten. Anhand der Daten sollen also Rückschlüsse auf den Prozess der zu diesen Daten geführt hat geschlossen werden. Dies wird mit folgenden Schritten gemacht\n\n1. __Parameterschätzung__: Bei der Parameterschätzung wird ein Wert geschätzt, der den Daten zugrundeliegt. Sie erlaubt das Quantifizieren eines Parameters, z.B. der Schätzung eines Mittelwerts.\n\n2. __Hypothesentests__: Hypothesentests vergleichen zwei Modelle, sie erlauben eine Entscheidung z.B. ist ein signifikanter Unterschied vorhanden oder nicht?\n\n# Frequentistische und Bayesianische Parameterschätzung\n\nIn der Frequentistischen Statistik wird angenommen, dass ein Parameter einen wahren (aber unbekannten) Wert hat. Die frequentistische Parameterschätzung ergibt eine Punktschätzung, der geschätzte Parameter hat damit genau __einen__ Wert und keine Wahrscheinlichkeitsverteilung. Daher dürfen keine Aussagen über die Wahrscheinlichkeit eines Parameters gemacht werden. Nur Ereignisse die wiederholt werden können eine Wahrscheinlichkeit (eine Häufigkeitsverteilung) haben.\n\nIn der Bayesianischen Statistik hingegen wird für jeden möglichen Parameterwert geschätzt, wie wahrscheinlich dieser einzelne Wert ist. Das bedeutet wir erhalten für jeden dieser Werte eine Wahrscheinlichkeit, diese wird in der Posterior-Verteilung zusammengefasst. Der Posterior Wahrscheinlichkeit beschreibt unser _degree of belief_, also unser aktuelles Wissen darüber, wie wahrscheinlich dieser Parameterwert wirklich hinter den Daten steckt. \n\n:::callout-caution\n\n## Hands-on: Frequentistisch oder Bayesianisch?\n\nOrdnen Sie die untenstehenden Aussagen dem frequentistischen bzw. dem baysianischen Ansatz zu:\n\n- \"Der Mittelwert liegt mit 95%-iger Wahrscheinlichkeit zwischen 0.75 und 0.85.\"\n\n- \"Wenn das Experiment 100 Mal wiederholt wird, ist der wahre Wert in 95% der Konfidenzintervalle enthalten.\"\n\n:::\n\nWir schauen uns die unterschiedlichen Ansätze der Parameterschätzung im Folgenden an einem Beispiel an. Wir haben bei einer Person z.B. beobachtet, dass Sie in 15 von 20 Trials korrekt geantwortet hat.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncorrect <- 15 # Anzahl korrekter Antworten\ntrials <- 20 # Anzahl Trials insgesamt\n```\n:::\n\n\n## Maximum-Likelihood Schätzung\n\n$\\theta$ ist der Parameterwert unter dem die beobachteten Daten am wahrscheinlichsten entstanden sind. Die beste Punktschätzung des Parameters $\\theta$, die wir machen können, wenn wir nur die Daten betrachten, und kein weiteres Vorwissen berücksichtigen, ist die Maximum-Likelihood Schätzung. \n\nMöchten wir also z.B. schätzen mit welcher Wahrscheinlichkeit die Person beim nächsten Trial eine richtige Antwort gibt, können wir dies aus den bisherigen Trials berechnen:\n\n$$\\theta = correct / all $$ \n\nWenn die Person also 15 Mal richtig geantwortet hat in insgesamt 20 Trials, wäre die Schätzung also\n\n$\\theta = 15 / 20 = 0.75$\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntheta <- correct / trials\ntheta\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.75\n```\n:::\n:::\n\nWir erhalten eine Punktschätzung (__einen__ Wert), die uns angibt mit welcher Wahrscheinlichkeit die Person beim nächsten Trial richtig antworten wird, nämlich 0.75, in 3/4 der Fälle.\n\nWenn man ganz viele Male diese Spiele wiederholen würde, dann würde man diese Messung am wahrscheinlichsten reproduzieren können, wenn man für $\\theta$ den Wert 0.75 einsetzt. \n\nDer grosse Nachteil einer Punktschätzung ist es, dass wir keine  Wahrscheinlichkeitsverteilung erhalten. Es gäbe auch noch viele andere Parameterwerte, die dieses Ergebnis von 15 korrekten Antworten in 20 Trials hervorbringen könnten, diese werden bei der Punktschätzung nicht beachtet. \n\nUm das zu veranschaulichen plotten wir die Wahrscheinlichkeit von 15 korrekten Antworten in 20 Trials für alle Werte welche $\\theta$ annehmen könnte. Diese Werte liegen zwischen 0 und 1, da wir von einer Wahrscheinlichkeit sprechen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(x = seq(from = 0, to = 1, by = .01)) %>% \n  mutate(density = dbinom(15, 20, x)) %>% \n  \n  ggplot(aes(x = x, ymin = 0, ymax = density)) +\n  geom_ribbon(size = 0, alpha = 1/4, fill = \"steelblue\") +\n  geom_vline(xintercept = theta, linetype = 2, linewidth = 1.2) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  coord_cartesian(xlim = c(0, 1)) +\n  xlab(\"Wahrscheinlichkeit\") +\n  theme(panel.grid = element_blank(),\n        legend.position = \"none\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n```\n:::\n\n::: {.cell-output-display}\n![](data_analysis_parameterestimates_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\nDie Punktschätzung von $\\theta$ wird mit der schwarzen gestrichelten Linie dargestellt. Die hellblaue Fläche zeigt, wie wahrscheinlich die einzelnen Werte jeweils sind (hier abgebildet sehen Sie _relative_ Wahrscheinlichkeiten.\n\n:::callout-caution\n\n## Hands-on: Punktschätzung \n\nDiskutieren Sie in kleinen Gruppen, wie sinnvoll es ist sich hier auf einen Wert festzulegen:\n\n- Wie genau denken Sie bildet die Punktschätzung die Realität ab?\n\n- Wie viel wahrscheinlicher ist das berechnete $\\theta$ von 0.75 im Vergleich zu einem $\\theta$ von 0.70?\n\n- Was kann das Schätzen der Wahrscheinlichkeit für alle Parameterwerte für einen Mehrwert bringen?\n:::\n\n## Posterior-Schätzung in der Bayesianischen Statistik\n\nIn der Bayesianischen Statistik wird die Wahrscheinkeitslehre angewandt, um die Wahrscheinlichkeit von Parameterwerten zu berechnen. Im Gegensatz zu der Frequentistischen Statistik wird nicht nur ein \"wahrer Wert\" geschätzt, sondern eine Verteilung. Es wird also für jeden möglichen Parameterwert eine Wahrscheinlichkeit geschätzt. \n\nDer Posterior wird also über alle möglichen Parameterwerte integriert, was ein wesentlicher Vorteil der Bayesian Statistik ist. So wird nicht nur der wahrscheinlichste Parameterwert berücksichtigt (Punktschätzung), sondern durch das Einbeziehen der ganzen Parameterverteilung können auch Nebenoptima und \"fast\" genauso wahrscheinliche Werte einbezogen\nwerden.\n\nUm die Wahrscheinlichkeit von Parametern zu berechnen wird in der Bayesianischen Statistik das Bayes Theorem verwendet. \n\n::: {.callout-note appearance=\"simple\"}\n\n## Bayes Theorem\n\nDas Bayes Theorem gibt die Formel für eine bedingte Wahrscheinlichkeit $P(A|B)$ an. \n\n$$ P(A|B) = \\frac{P(B|A)⋅P(A)}{P(B)} $$\n\nDas kann gelesen werden als: \n\n\"Die Wahrscheinlichkeit eines Ereignisses A unter der Bedingung, dass ein Ereignis B wahr ist, ist gleich der a priori Wahrscheinlichkeit, dass A wahr ist, multipliziert mit der Wahrscheinlichkeit, dass B eintritt, wenn A wahr ist. Dividiert wird das Ganze durch die Wahrscheinlichkeit, dass B eintritt, egal ob A wahr oder falsch ist.\"\n:::\n\nDas bedeutet, um eine Bayesianische Parameterschätzung zu machen, müssen wir Vorwissen integrieren. Dies tun wir in Form einer Prior-Verteilung. Ein sehr simple Variante ist, den Prior ist so zu wählen, dass er allen möglichen Werten dieselbe Wahrscheinlichkeit zuschreibt (wie in der Grafik unten). Dies ist aber selten empfehlenswert, darauf wird später noch eingegangen.\n\n\n__Parameterschätzung__\n\n![](img/theta_posterior.png)\n\n<!-- | Ansatz | Parameterschätzung | Hypothesentests | Statistische Kennzahlen | -->\n<!-- |------|------|------|------| -->\n<!-- | Frequentistisch | wahrer Wert wird geschätzt | ahrscheinlichkeit der Daten zu berechnen, unter der Annahme dass die Nullhypothese wahr ist | p-Werte, Konfidenzintervall | -->\n<!-- | Ba -->\n\n\n:::callout-caution\n\n## Hands-on: Bayesianische Parameterschätzung in JASP\n\nAktivieren Sie in JASP das Modul \"Learn Bayes\". Wählen Sie unter \"Learn Bayes\": \"Binomial Estimation\". Wählen Sie \"Enter Sequence\".\n\nStellen Sie sich vor, sie untersuchen eine Person, welche behauptet, extrasensorische Fähigkeiten zu besitzen. Diese Person behauptet, dass vorhersagen kann, auf welcher Seite eine Münze landet, bevor sie geworfen wurde. Sie werfen die Münze 10 mal und die Person macht 7 korrekte Vorhersagen.\n\n- Welche Fragen könnten von Interesse sein?\n\n- Wie würden Sie die Behauptung der Person überprüfen?\n\n- Glauben Sie, dass die Person über extra-sensorische Fähigkeiten verfügt? Sind Sie skeptisch? \n- Unter den Dropdown Menus Model, Prior and Posterior Distributions und Plots gibt es verschiedene Checkboxes. Versuchen Sie herauszufinden, was diese bewirken.\n\n- Wie können Sie Ihr Vorwissen in die Analyse einbeziehen? Wie verbinden Sie Ihr Vorwissen mit den beobachteten Daten? Passen Sie Ihren Prior für $\\theta$ an:\n\n__Beta Verteilungen__\n\n![](img/betadistributions.png)\n\n:::\n\n\n## Wrap-up\n\nZusammenfassend kann gesagt werden:\n\n- In der frequentistischen Statistik wird angenommen, dass der Parameter einen _wahren Wert_ hat, den wir aber nicht kennen. Wir erhalten eine Punktschätzung für den Parameter und können keine Aussage über die Wahrscheinlichkeit eines Parameterwerts machen. Der 95%-CI (__confidence interval__) sagt aus, dass bei Wiederholung des Experiments der \"wahre\" Parameterwert in 95% der Konfidenzintervalle enthalten sein wird.\n\n- In der bayesianischen Statistik nehmen wir an, dass der Parameter eine Wahrscheinlichkeitsverteilung hat, die wir schätzen können. Es muss zusätzlich eine Priorverteilung festgelegt werden. Wir erhalten eine Posterior Verteilung für die Parameterwerte und können eine Aussage über Wahrscheinlichkeit eines Parameterwerts oder eines Modelles machen. Der 95%-CI (__credible interval__) enthält zu 95% den \"wahren\" Parameterwert.\n\n<aside>\"Wahr\" bedeutet hier, den Parameterwert der  (wenn wir ein passendes Modell verwendet haben)  zu diesen Daten geführt hat.</aside>\n",
    "supporting": [
      "data_analysis_parameterestimates_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}