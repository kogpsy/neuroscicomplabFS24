{
  "hash": "181522e750cdcddc17b6ee6b992babe4",
  "result": {
    "markdown": "---\ntitle: \"Data Analysis 1\"\ndescription: \"Datengenerierende Prozesse\"\nauthor:\n  - name: Gerda Wyssen\n    affiliation: Kognitive Psychologie, Wahrnehmung und Methodenlehre, Universität Bern \n    affiliation-url: https://www.kog.psy.unibe.ch\n    orcid: 0000-0001-7427-3149\n  - name: Andrew Ellis\n    url: https://github.com/awellis\n    affiliation: Kognitive Psychologie, Wahrnehmung und Methodenlehre, Universität Bern \n    affiliation_url: https://www.kog.psy.unibe.ch\n    orcid_id: 0000-0002-2788-936X\n  - name: Daniel Fitze\n    affiliation: Kognitive Psychologie, Wahrnehmung und Methodenlehre, Universität Bern \n    affiliation-url: https://www.kog.psy.unibe.ch\n    orcid: 0000-0003-0158-7459  \nlicense: CC BY\ncitation: true\nbibliography: ../../bibliography_nsci24.bib\nformat:\n    html:\n        toc: true\n        code-link: true\n---\n\n\n\n\nIn der Forschung und Diagnostik interessieren uns oft Eigenschaften eines Prozesses oder einer Person, welche wir nicht direkt messen können. Deshalb werden Testverfahren und Experimente angewendet um diese latenten Variablen messbar zu machen. Mit statistischen Verfahren wird dann versucht aus den gemessenen Daten Informationen über die interessierende Eigenschaft zu erhalten. \n\n<!-- Uns kann beispielsweise die Aufmerksamkeitsleistung interessieren, welche wir mit einem Testverfahren für Aufmerksamkeit zu messen versuchen. Eine Neurowissenschaftlerin, welche sich für den Prozess von Aufmerksamkeit interessiert, würde versuchen die Aufmerksamkeitsleistung von vielen Leuten unter verschiedenen Bedingungen zu messen um zu untersuchen, durch was Aufmerksamkeit beeinflusst wird.  Ein klinischer Neuropsychologe hingegen hätte vielleicht das Ziel festzustellen, ob die Aufmerksamkeitsleistung einer Person von der Norm abweicht, beispielsweise weil sie durch einen Unfall eine Kopfverletzung erlitten hat. Beide messen Daten und beide ziehen aus den gemessenen Daten Rückschlüsse auf eine unterliegende Eigenschaft eines Prozesses oder einer Person.  -->\n\n# Herausforderungen in der Analyse von neurowissenschaftlichen Daten\n\nNeurowissenschaftliche Datensätze haben oft folgende Eigenschaften, welche Herausforderungen in der Datenanalyse führen:\n\n- Kleine Stichprobengrössen (z.B. aufgrund teurer Datenerhebung oder Patientengruppen die schwieriger zu rekrutieren sind).\n\n- Viel Heterogenität / Rauschen (z.B. weil der zu untersuchende Prozess schwierig zu isolieren ist, weil Personen sich sehr unterschiedlich verhalten)\n\n- Teure Datenerhebung und damit hoher Druck Resultate zu generieren sowie oft keine Möglichkeit das Experiment zu wiederholen  (wichtig daher die gute Planung der Analyse sowie Vermeidung von inkonklusive Resultaten)\n\n## Vorbereitung\n\n:::callout-caution\n## Hands-on: Reaktivierung Statistikwissen\n\n1. Besprechen Sie in kleinen Gruppen folgende Fragen:\n\n- Was ist eine Null-, was eine Alternativhypothese?\n\n- Was bedeutet die Distanz zwischen den beiden Mittelwerten?\n\n- Was ist statistische Power?\n\n- Welche Rolle spielt die Stichprobengröße\n\n- Was ist ein p-Wert?\n\n- Was sind Typ I und Typ II Fehler?\n\n- Welche Fragen können Sie mit einem Nullhypothesen-Test beantworten?\n\n\n2. Können Sie die Begrifflichkeiten in dieser Grafik einordnen?\n\n![](img/reactivationstatistics.png)\n\n3. Überlegen Sie sich, was Null- und Alternativhypothese in unseren Experimenten sein können?\n\n_[10 Minuten]_\n\n:::\n\n<aside>Sie können zur Beantwortung dieser Fragen z.B. die [Interaktive Visualisierung \"Understanding Statistical Power and Significance Testing\"](https://rpsychologist.com/d3/nhst/) nutzen.</aside>\n\n::: {.callout-note appearance=\"simple\"}\n\n## Projekt und Daten herunterladen\n\n[Hier]() finden Sie das R-Projekt mit Daten zum herunterladen.\n\nLesen Sie anschliessend die Daten ein:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Projekt und Daten für die folgenden Analysen\nlibrary(tidyverse)\nd_stroop <- read_csv(\"../../data/data_stroop_clean/data/dataset_stroop_clean.csv\") |>\n    mutate(across(where(is.character), as.factor)) |>\n    mutate(congruent = as.factor(congruent))\n```\n:::\n\n:::\n\n# Parameterschätzung und Hypothesentests\n\nNach dem Data Cleaning und Preprocessing geht es darum, welche Informationen die Daten über den zu untersuchenden Prozess beinhalten. Anhand der Daten sollen also Rückschlüsse auf den Prozess der zu diesen Daten geführt hat geschlossen werden. Dies wird mit folgenden Schritten gemacht\n\n1. __Parameterschätzung__: Bei der Parameterschätzung wird ein Wert geschätzt, der den Daten zugrundeliegt (z.B. ein Mittelwert).\n\n2. __Hypothesentests__: Hypothesentests erlauben die Entscheidung zwischen Modellen / Alternativen. \n\n# Datengenerierende Prozesse, Simulation und Analyse\n\n## DAGs\n\nEin DAG (_directed acyclic graph_) eignet sich für die Darstellung komplexer Zusammenhänge in Daten und Prozessen. Die Kreise (_nodes_) werden für einzelne Elemente verwendet und die Pfeile (_arrows_) beschreiben die Beziehung zwischen den Elementen. Die Darstellung beschreibt einen Prozess also mit gerichteten (_directed_) und nicht zyklischen (_acyclic_) Beziehungen, es kommen also keine Kreisläufe vor.\n\nMit einem DAG können wir veranschaulichen, welche Variablen einander beeinflussen. Wir können beispielsweise annehmen, dass die Farbe-Wort-Kongruenz im Stroop Task beeinflusst, wie korrekt die Aufgabe gelöst werden kann, die Farbe des Wortes zu nennen.\n\nDAG condition --> accuracy\n\nWir können aber mit DAGs auch unsere statistische Analyse planen und visualisieren. Hierfür zeichnen wir zuerst unsere abhängige Variable (_AV_) in einen Kreis ($y$).\n\n\nDAG mit y\n\nDer nächste Schritt ist es die Daten innerhalb einer Variable zu beschreiben. Eine einfache Form das zu tun ist es eine Verteilung zu definieren. Die am häufigsten verwendete Verteilung in statistischen Analysen ist die Normalverteilung. Die Annahme einer Normalverteilung ermöglicht es uns, mit nur 2 Parametern die Daten in der Variable  zu beschreiben (natürlich ist das nur eine Annäherung aber meistens eine genügend gute): dem Mittelwert ($\\mu$) und der Standardabweichung ($\\sigma$).\n\nDAG mit mu und sigma\n\nWir können weiter annehmen, dass die Verteilung der Daten dadurch\nbeeinflusst wird unter welcher Bedingung die Aufgabe gelöst wird.\nEs muss nun definiert werden, was von der Bedingung beeinflusst wird, wir entscheiden uns für den Mittelwert. Der Mittelwert ($\\mu$) der Verteilung von $\\y$ wird als durch die Bedingung ($\\beta$) beeinflusst.\n\nDAG mit beta\n\n\nWenn wir nun den Einfluss der Bedingung untersuchen möchten, könnten wir uns fragen, wie stark diese eine Veränderung im MIttelwert der Verteilung bewirkt. Genau dies tun wir bei Mittelwertsvergleichen wie z.B. bei t-Tests.\n\n### DAG für die Stroop Daten\n\nAngewandt auf unser Stroop-Experiment würden wir z.B. die Antwortgeschwindigkeit (`rt`) als abhängige Variable und die Kongruenzbedingung (`condition`) als unabhängige Variable definieren. \n\nUm die Verteilung der Daten zu bestimmen können die Daten in `R` geplottet werden, z.B. mit `geom_histogram`. Das Argument `binwidth` bestimmt, wie breit ein Balken wird (hier 50 ms).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_stroop |>\n    ggplot(aes(x = rt)) +\n    geom_histogram(binwidth = 0.05) +\n    theme_minimal()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 19 rows containing non-finite outside the scale range\n(`stat_bin()`).\n```\n:::\n\n::: {.cell-output-display}\n![](data_analysis_intro1_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nDiese Verteilung könnte beispielsweise mit einer Normalverteilung beschrieben werden. Der Mittelwert und die Standardabweichung können wir uns ausrechnen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# clean dataset first\nmu = mean(d_stroop$rt, na.rm = TRUE)\nsigma = sd(d_stroop$rt, na.rm = FALSE)\n```\n:::\n\n\nUm zu schauen, wie gut diese Verteilung unsere DAten beschreibt können wir die beiden übereinander plotten:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_stroop |>\n    ggplot(aes(x = rt)) +\n    geom_histogram(binwidth = 0.05) +\n    # insert here\n    theme_minimal()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 19 rows containing non-finite outside the scale range\n(`stat_bin()`).\n```\n:::\n\n::: {.cell-output-display}\n![](data_analysis_intro1_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n:::callout-caution\n\n## Hands-on: Verteilungen\n\nWelche Verteilung passt um die oben geplotteten Daten zu beschreiben?\n\n- Gehen Sie auf [Distribution Zoo]() und versuchen Sie eine passende Verteilung zu finden.\n\n- Prüfen Sie Ihre Verteilung indem Sie unten an den obigen Plot diese Verteilung mit gewählten Parametern folgenden Code einfügen:\n\n```\n+ ...\n```\n\n###, Formeln, \n\nHands-on: 1h\n\nDAGs zeichnen\n\n- 1. Kreis: AV\n\n- Verteilung herausfinden (plotten): mit distribution zoo abgleichen Verteilung suchen die passt und über unseren Daten legen mit der Funktion die mir Daniel noch schickt.\n\n- Weitere Kreise zeichnen, benennen\n\n--> Unterschied Deskriptiv/Inferenz (Unsicherheit)\n--> Parameterschätzung: Freq Bay\n\n\n--> Hypothesentest\n\n\n## Parameterschätzung: Frequentistischer und Bayesianischer Ansatz\n\n\nWird ein Parameter mit der Frequentistischen Statistik geschätzt, erhält man eine Punktschätzung, der Parameter hat also nur __einen__ Wert. Nur Ereignisse die wiederholt werden können eine Wahrscheinlichkeit (eine Häufigkeitsverteilung) haben.\n\nIn der Bayesianischen Statsitik hingegen wird für jeden möglichen Parameterwert geschätzt, wie wahrscheinlich dieser einzelne Wert ist. Das bedeutet wir erhalten für jeden dieser Werte eine Wahrscheinlichkeit, dies wird in der Posterior-Verteilung zusammengefasst. Der Posterior Wahrscheinlichkeit beschreibt unser _degree of belief_, also unser aktuelles Wissen darüber, wie wahrscheinlich dieser Parameterwert wirklich hinter den Daten steckt. \n\n      In the Bayesian worldview, probability quantifies degree of belief. More specificcally, our uncertainty is expressed as a probability distribution. Probability quantifies knowledge, and is not a fundamental property of things.\n\n\nWir schauen uns dies im Folgenden an einem Beispiel an. Wir haben bei einer Person z.B. folgende Daten beobachtet:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncorrect <- 45 # Anzahl korrekter Antworten\ntrials <- 60 # Anzahl Trials insgesamt\n```\n:::\n\n\nUnd möchten nun \n\n\n## Maximum-Likelihood Schätzung\n\nUm den Parameter zu schätzen können verschiedene Methoden verwendet werden. Die bekannteste Methode ist die Maximum-Likelihood Schätzung.\n\nDie Maximum Likelihood Schätzung ergibt eine Punktschätzung des Parameters $\\theta$. Dies ist der Parameterwert unter dem die beobachteten Daten am wahrscheinlichsten entstanden sind. Der grosse Nachteil einer Punktschätzung ist es, dass wir keine Wahrscheinlichkeitsverteilung erhalten. Es gäbe auch noch viele andere Parameterwerte, die dieses Ergebnis von 6 Siegen in 9 Spielen hervorbringen könnten, diese werden bei der Punktschätzung nicht beachtet. \n\nMöchten wir also z.B. schätzen mit welcher Wahrscheinlichkeit die Person beim nächsten Trial eine richtige Antwort gibt, können wir dies aus den bisherigen Trials berechnen:\n\n$$\\theta = correct / all $$ \n\nWenn die Person also 45 Mal richtig geantwortet hat in insgesamt 60 Trials, wäre die Schätzung also\n\n$\\theta = 45 / 60 = 0.75$\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntheta <- correct / trials\ntheta\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.75\n```\n:::\n:::\n\n\nWir erhalten eine Punktschätzung (__einen__ Wert)s, die uns angibt mit welcher Wahrscheinlichkeit die Person beim nächsten Trial richtig antworten wird, nämlich 0.75, in 3/4 der Fälle.\n\nWenn man ganz viele Male diese Spiele wiederholen würde, dann würde man diese Messung am wahrscheinlichsten reproduzieren können, wenn man für $\\theta$ den Wert 0.75 einsetzt. \n\nUm das zu veranschaulichen plotten wir die Wahrscheinlichkeit von 6 Siegen in 9 Spielen für alle Werte welche $\\theta$ annehmen könnte. Diese Werte liegen zwischen 0 und 1, da wir von einer Wahrscheinlichkeit sprechen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(x = seq(from = 0, to = 1, by = .01)) %>% \n  mutate(density = dbinom(6, 9, x)) %>% \n  \n  ggplot(aes(x = x, ymin = 0, ymax = density)) +\n  geom_ribbon(size = 0, alpha = 1/4, fill = \"steelblue\") +\n  geom_vline(xintercept = theta, linetype = 2, size = 1.2) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  coord_cartesian(xlim = c(0, 1)) +\n  xlab(\"Wahrscheinlichkeit\") +\n  theme(panel.grid = element_blank(),\n        legend.position = \"none\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n```\n:::\n\n::: {.cell-output-display}\n![](data_analysis_intro1_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n:::callout-caution\n\n## Hands-on: Punktschätzung \n\nDiskutieren Sie in kleinen Gruppen, wie sinnvoll es ist sich hier auf einen Wert festzulegen:\n\n- Wie genau denken Sie bildet diese Schätzung die Realität ab?\n\n- Wie viel wahrscheinlicher ist das berechnete $\\theta$ von 0.75 im Vergleich zu einem $\\theta$ von 0.74?\n\n:::\n\nDie Punktschätzung von $\\theta$ wird mit der schwarzen gestrichelten Linie dargestellt. Doch eigentlich wissen wir mehr: Betrachtet man die hellblaue Fläche wird deutlich, dass auch etwas kleinere oder grössere Werte als die Punktschätzung mit grosser Wahrscheinlichkeit diese Daten hervorgebracht haben könnten. \n\n## Posterior-Schätzung in der Bayesianischen Statistik\n\nIn der Bayesianischen Statistik wird die Wahrscheinkeitslehre angewandt, um die Wahrscheinlichkeit von Parameterwerten zu berechnen. Im Gegensatz zu der Frequentistischen Statistik wird nicht nur ein \"wahrer Wert\" geschätzt, sondern eine Verteilung. Es wird also für jeden möglichen Parameterwert eine Wahrscheinlichkeit geschätzt, mit der dieser Wert der richtige sein könnte. (Richtig bedeutet hier: der Wert der diese Daten generiert hat.) \n\nDer Posterior wird also über alle möglichen Parameterwerte integriert, was ein wesentlicher Vorteil der Bayesian Statistik ist, dass eben nicht nur der wahrscheinlichste Parameterwert berücksichtigt wird (Punktschätzung), sondern sondern dass durch das Einbeziehen der ganzen Parameterverteilung auch Nebenoptima und \"fast\" genauso wahrscheinliche Werte berücksichtigt\nwerden.\n\n\nZusammenfassend kann also gesagt werden:\n\n- In der frequentistischen Statistik wird angenommen, dass der Parameter einen _wahren Wert_ hat, den wir aber nicht kennen. Wir erhalten eine Punktschätzung (mit Fehler) für den Parameter.\n\n -In der bayesianischen Statistik nehmen wir an, dass der Parameter eine Wahrscheinlichkeitsverteilung hat, die wir schätzen können (also nicht _einen_ wahren Wert).\n\n\n\n| Ansatz | Parameterschätzung | Hypothesentests | Statistische Kennzahlen |\n|------|------|------|------|\n| Frequentistisch | wahrer Wert wird geschätzt | ahrscheinlichkeit der Daten zu berechnen, unter der Annahme dass die Nullhypothese wahr ist | p-Werte, Konfidenzintervall |\n| Ba\n\n\n\n\n",
    "supporting": [
      "data_analysis_intro1_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}