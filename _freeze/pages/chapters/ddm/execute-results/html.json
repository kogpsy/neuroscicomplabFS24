{
  "hash": "5641adef3f662f6352c14b02bcf45b33",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Drift Diffusion Modell\"\nauthor:\n  - name: Daniel Fitze\n    # url: https://github.com/awellis\n    affiliation: Kognitive Psychologie, Wahrnehmung und Methodenlehre, Universität Bern \n    affiliation-url: https://www.kog.psy.unibe.ch\n    orcid: 0000-0003-0158-7459  \n  - name: Andrew Ellis\n    # url: https://github.com/awellis\n    affiliation: Kognitive Psychologie, Wahrnehmung und Methodenlehre, Universität Bern \n    affiliation-url: https://www.kog.psy.unibe.ch\n    orcid: 0000-0002-2788-936X\n  - name: Gerda Wyssen\n    # url: https://github.com/awellis\n    affiliation: Kognitive Psychologie, Wahrnehmung und Methodenlehre, Universität Bern \n    affiliation-url: https://www.kog.psy.unibe.ch\n    orcid: 0000-0001-7427-3149\nlicense: CC BY-SA 4.0\nformat: html\nengine: knitr\n# filters:\n#   - webr\n---\n\n::: {.cell}\n\n:::\n\n\n\n## Modelle Rückblick\nWir haben zwei mögliche Modelle (vgl. DAG's unten) angeschaut, welche die Leistung der Versuchspersonen im Random Dot Task beschreiben / vorhersagen können.\nBeide Modelle machen, basierend auf den Antworten, eine Aussage über die Sensitivität der Versuchspersonen. Für beide Modelle, die wir bis jetzt betrachtet haben, notieren wir die Antwort der Versuchsperson (`links` oder `rechts`) in jedem Trial des Random Dot Experiments. Basierend auf diesen Daten kann die Sensitivität (`%-Correct`, `d'`) geschätzt werden. \n\n\n:::: {layout=\"[ 50, 50]\"}\n:::{}\n\n\n```{mermaid}\n%%| fig-align: center\nflowchart TD\n  %%c((Condition)):::A --> r\n  s((%-Correct)):::A --> r((resp)):::B\n  \n  \n  classDef A fill:#ffffff, r:45px\n  classDef B fill:#e5e4e4, r:45px\n```\n\n\n:::\n:::{}\n\n\n```{mermaid}\n%%| fig-align: center\nflowchart TD\n  %%c((Condition)):::A --> r\n  c((c)):::A --> r\n  s((d')):::A --> r((resp)):::B\n  \n  classDef A fill:#ffffff, r:30px\n  classDef B fill:#e5e4e4, r:30px\n```\n\n\n:::\n::::\n\n## Evidenz Akkumulation\nNeben der Antwort der Versuchspersonen (`links`, `rechts`) haben wir auch die Zeit (`rt`) gemessen, welche benötigt wurde um diese Antworten zu geben. Diese Information wurde in den vorherigen Modellen nicht berücksichtigt. \n\nJetzt schauen wir uns genauer an, wie sich eine Entscheidung innerhalb eines Trials entwickelt und simulieren diesen Prozess in R. Dazu nehmen wir an, dass die Zeit in ganz kleine Schritte $\\Delta_t$ unterteilt ist (diskrete Zeit). Ausserdem gehen wir davon aus, dass die Person den Stimulus verarbeitet und über die Zeit Evidenz akkumuliert (sequential sampling). Diese Evidenz wird in einer Decision Variable gesammelt.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](ddm_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\nWir modellieren die aktuelle Decision Variable zu Zeitpunkt $t$ als normalverteilte Zufallszahl, bei der die `driftrate` den Mittelwert der Evidenz repräsentiert, und `sd` die Standardabweichung.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndriftrate = 0.5\nsd = 0.1\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nevidence = rnorm(n = 1, mean = driftrate, sd = sd)\nevidence\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.6254446\n```\n\n\n:::\n:::\n\n\nDies bedeutet, dass zum Zeitpunkt $t$ die Evidenz ungefähr 0.63 beträgt. Da die Evidenz die durchschnittliche Steigung repräsentiert, wird Evidenz $>0$ dazu führen, dass ein Schritt in Richtung der oberen Grenze gemacht wird. Wäre die Evidenz negativ, wird ein Schritt nach unten gemacht. Da die Evidenz aus einer Normalverteilung gezogen wird, ist es also möglich, dass die Evidenz zufällig negativ wird, obwohl die drift rate, d.h. die Repräsentation der Stimulusstärke, positiv ist.\n\n:::{.callout-note}\nEs wird angenommen, dass dieser Aspekt einigermassen gut die Vorgänge im Gehirn abbildet, da die neuronalen Antworten auf einen Reiz variabel sind (dies bedeutet, dass Neurone immer unterschiedlich auf einen Reiz reagieren, auch wenn dieser gleich bleibt).\n:::\n\n\nWenn wir dieses Prozess nun über einen Zeitraum wiederholen, und die `evidence` Werte aufsummieren, erhalten wir die *decision variable*. Diese sieht aus wie ein *random walk* mit einem Drift in die Richtung der durchschnittlichen Evidenz.\n\n\n## Random walk simulieren\n\nEin random walk ist das Resultat der Aufsummierung von Zufallszahlen. Wir können das in R selbst ausprobieren. Dazu simulieren wir einen random walk mit 100 Zeitschritten. Wir beginnen bei $0$, ziehen 99 normalverteilte Zufallszahlen und berechnen die kumulierte Summe.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(546)\n\n# hier z.B> standardnormalverteilte Zahlen\nzufallszahlen_1 = c(0, rnorm(99, 0, 1))\nrandom_walk_1 = cumsum(zufallszahlen_1)\n\nplot(1:100, random_walk_1, type = \"s\", col = \"#7fc97f\", \n     ylim=c(-10,30), lwd = 2, \n     xlab = \"Zeit\", ylab=\"Random Walk\")\n```\n\n::: {.cell-output-display}\n![](ddm_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nDieser random walk hat keinen Trend, weil wir immer aus einer Normalverteilung mit Mittelwert $\\mu=0$ ziehen. Wenn wir stattdessen aus einer Verteilung mit $\\mu=0.1$ ziehen, erhalten wir einen positiven Trend.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nzufallszahlen_2 = c(0, rnorm(99, 0.3, 1))\nrandom_walk_2 = cumsum(zufallszahlen_2)\n\nplot(1:100, random_walk_1, type = \"s\", col = \"#7fc97f\", \n     ylim=c(-10,30), lwd = 2, \n     xlab = \"Zeit\", ylab=\"Random Walk\")\nlines(1:100, random_walk_2, pch = 18, col = \"#beaed4\", \n      type = \"s\", lwd = 2)\n\nlegend(\"topleft\", legend=c(\"Ohne Trend\", \"Mit Trend\"),\n       col=c(\"#7fc97f\", \"#beaed4\"), lty = c(1, 1))\n```\n\n::: {.cell-output-display}\n![](ddm_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n## Evidenzakkumulierung\n\nDie Evidenzakkumulierung wird analog modelliert. Wenn wir explizit die Zeitschritte als Iterationen aufschreiben, können wir dies in R mit einer `for` Loop machen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndriftrate = 0.5\nsd = 0.1\n\nn_steps = 10\nevidence = rep(NA, n_steps)\n\ndv = rep(NA, n_steps)\n\ntime_steps = 1:n_steps\n\n# Wir ziehen den ersten Wert aus der Verteilung\nevidence[1] = rnorm(1, mean = driftrate, sd = sd)\ndv[1] = evidence[1]\n\n# für jeden weitern Zeitpunkt ziehen wir wieder eine Zufallszahl und addieren zur kumulierten DV\nfor (t in 2:n_steps) {\n    evidence[t] = rnorm(1, mean = driftrate, sd = sd)\n    dv[t] = dv[t-1] + evidence[t]\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(time_steps, evidence, dv) |> \n    pivot_longer(c(evidence, dv), names_to = \"type\", values_to = \"value\") |> \n    ggplot(aes(time_steps, value, linetype = type, color = type)) +\n    geom_line() +\n    geom_point(size = 4) +\n    scale_color_viridis_d(begin = 0.2, end = 0.5)\n```\n\n::: {.cell-output-display}\n![](ddm_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\nDie Decision Variable `dv` repräsentiert nun die kumulierten Evidenz, aufgrund dessen das Gehirn eine Entscheiung treffen kann. Wenn die Decision Variable entweder grösser als die ober Grenze ist, oder kleiner als die untere Grenze, wird die Evidenzakkumulierung abgebrochen, und eine Antwort wird ausgelöst. Wir können nun noch die \"non-decision time\" hinzufügen, und den Anfangspunkt der Evidenzakkumulierung. Dieser Anfangspunkt ist ein sehr wichtiger Parameter, denn wenn der Anfagnspunkt nicht genau in der Mitte zwischen den beiden Grenzen liegt, dann braucht es natürlich weniger Evindenz, um die Grenze zu erreichen, welche näher beim Anfangspunkt liegt.\n\n\n::: {.panel-tabset}\n\n## Model Parameters\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|Parameter           |Bedeutung                             |Anwendung                                           |\n|:-------------------|:-------------------------------------|:---------------------------------------------------|\n|drift rate          |Qualität der Evidenz pro Zeiteinheit  |Task Schwierigkeit, Fähigkeit                       |\n|bias                |Anfangspunkt der Evidenzakkumulierung |A priori Präferenz für eine der beiden Alternativen |\n|boundary separation |Vorsicht (caution)                    |Speed-Accuracy Trade-off                            |\n|non-decision time   |Verzögerung                           |Periphere Prozesse                                  |\n\n\n:::\n:::\n\n\n## Function\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndrift_diffusion = function(bias = 0.5,\n                            driftrate = 0.8,\n                            decision_boundary = 2,\n                            ndt = 0.5,\n                            diffvar = 0.1,\n                            dt = 0.001,\n                            max_time = 6) {\n\n    assertthat::assert_that(diffvar > 0)\n\n    # rescale bias so that 0.5 lies halfway between upper and lower bound\n    bias = as.numeric(2 * decision_boundary * bias - decision_boundary)\n\n    # initialize time_steps and dv\n    time_steps = max_time/dt\n    dv = array(dim = time_steps)\n\n    # start acumulating from bias (starting point)\n    dv[1] = rnorm(1, mean = bias, sd = sqrt(dt))\n\n    for (j in 2:time_steps) {\n\n        # non-decision time\n        if (j <= ndt/dt) {\n            dv[j] = dv[j-1]\n        }\n        else {\n            error = rnorm(1, 0, sqrt(diffvar * dt))\n            dv[j] = dv[j-1] + driftrate * dt + error  # Cobb & Zacks (1985), Eq. 1.14\n            if (abs(dv[j]) > decision_boundary) {\n                dv[j] = dplyr::if_else(dv[j] > 0,\n                                 min(dv[j], decision_boundary),\n                                 max(dv[j], -decision_boundary))\n                break()\n            }\n        }\n    }\n    d = dplyr::tibble(time = round(seq_along(dv) * dt, 3),\n                         dv = dv,\n                         steps = seq_along(dv),\n                         driftrate = driftrate,\n                         decision_boundary = decision_boundary,\n                         bias = bias,\n                         ndt = ndt)\n    return(d)\n}\n```\n:::\n\n\n:::\n\n\n\n\n## Auswirkungen der Parameter\n\nWir können nun einige Trials plotten, um den Effekt dieser Parameter zu visualisieren.\n\n\n### Drift rate\n\nWir fangen an mit der drift rate. Wenn diese $>> 0$ ist, wird die Obergrenze schnell erreicht, und es wird wenige Fehler geben. Ist die drift rate kleiner, aber immer noch $> 0$, wird die durschnittliche Zeit länger, um eine korrekte Antwort zu geben.\n\n\n::: {.cell code_folding='true'}\n\n```{.r .cell-code}\nset.seed(829)\n\nslow = drift_diffusion(driftrate = 0.8) |> mutate(type = \"slow\")\nfast = drift_diffusion(driftrate = 1.2) |> mutate(type = \"fast\")\n\nfastslow = bind_rows(fast, slow) \n\nfastslow |> \n    ggplot(aes(time, dv, color = type)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    geom_line() +\n    scale_color_viridis_d(end = 0.8) +\n    geom_hline(yintercept = c(-2, 2), color = \"black\", size = 1) +\n    ggtitle(\"Grosse vs. kleine Drift Rate\")\n```\n\n::: {.cell-output-display}\n![](ddm_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n### Bias\n\nWenn der bias $>0.5$ ist, wird die Obergrenze schneller erreicht. Hier gibt es nun eine Interaktion mit der drift rate---ist diese klein, und der bias $<0.5$, ist die Chance, schnelle Fehler zu machen erhöht.\n\n\n::: {.cell code_folding='true'}\n\n```{.r .cell-code}\nset.seed(29)\n\nunbiased = drift_diffusion(bias = 0.5) |> mutate(type = \"unbiased\")\nupbiased = drift_diffusion(bias = 0.7) |> mutate(type = \"upbiased\")\ndownbiased = drift_diffusion(bias = 0.3) |> mutate(type = \"downbiased\")\n\n\n\nbias = bind_rows(unbiased, upbiased, downbiased) \n\nbias |> \n    ggplot(aes(time, dv, color = type)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    geom_line() +\n    scale_color_viridis_d(end = 0.8) +\n    geom_hline(yintercept = c(-2, 2), color = \"black\", size = 1) +\n    ggtitle(\"Anfangspunkte\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 8605 rows containing missing values or values outside the scale range\n(`geom_line()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](ddm_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\n### Boundary separation\n\nLiegen die Grenzen weiter auseinander, braucht es mehr akkumulierte Evidenz, um eine der Grenzen zu erreichen. Dies führt dazu, dass weniger Fehler gemacht werden, da die zufällige Fluktuation über längere Zeit hinweg einen weniger starken Einfluss hat. Deshalb kann eine Verschiebung der Grenzen den Speed-Accuracy Trade-off erklären.\n\n\n\n::: {.cell code_folding='true'}\n\n```{.r .cell-code}\nset.seed(84)\n\ncarefree = drift_diffusion(decision_boundary = 1.6) |> mutate(type = \"carefree\")\ncautious = drift_diffusion(decision_boundary = 2.1) |> mutate(type = \"cautious\")\n\ncautiouscareless = bind_rows(carefree, cautious) \n\ndecision_boundaries = tribble(~type, ~decision_boundary,\n                               \"carefree\", 1.6,\n                               \"cautious\", 2.1)\ncautiouscareless |> \n    ggplot(aes(time, dv, color = type)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    geom_line() +\n    scale_color_viridis_d(end = 0.8) +\n    geom_hline(aes(yintercept = decision_boundary, color = type), data = decision_boundaries) +\n    geom_hline(aes(yintercept = -decision_boundary, color = type), data = decision_boundaries) +\n    ggtitle(\"Unterschiede im Abstand zwischen den Grenzen\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 7157 rows containing missing values or values outside the scale range\n(`geom_line()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](ddm_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n### Non-decision time\n\nEine Veränderung der non-decision time hat eine Auswirkung auf die durschnittliche Reaktionszeit, hat aber keinen Einfluss auf die Fehlerrate.\n\n\n\n::: {.cell code_folding='true'}\n\n```{.r .cell-code}\nset.seed(4534)\n\nlongndt = drift_diffusion(ndt = 0.7) |> mutate(type = \"longndt\")\nshortndt = drift_diffusion(ndt = 0.2) |> mutate(type = \"shortndt\")\n\nndt = bind_rows(longndt, shortndt) \n\nndts = tribble(~type, ~ndt,\n                \"longndt\", 0.7,\n                \"shortndt\", 0.2)\n\nndt |> \n    ggplot(aes(time, dv, color = type)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    geom_line() +\n    scale_color_viridis_d(end = 0.8) +\n    geom_vline(aes(xintercept = ndt, color = type), data = ndts) +\n    geom_hline(yintercept = c(-2, 2), color = \"black\", size = 1) +\n    ggtitle(\"Unterschiede in der Non-Decision Time\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 6407 rows containing missing values or values outside the scale range\n(`geom_line()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](ddm_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\n:::callout-caution\n## Unsere Daten\n\n\n::: {.panel-tabset}\n\n### DDM Random Dot Experiment\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|term        | estimate|\n|:-----------|--------:|\n|Drift rate  |     0.01|\n|bs_accuracy |     3.07|\n|bs_speed    |     2.48|\n|ndt         |     0.00|\n|bias        |     0.50|\n\n\n:::\n:::\n\n\n\n### Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(brms)\nlibrary(cmdstanr)\n\nfit = brm(bf(rt | dec(resp) ~ 0,\n             bs ~ 0 + condition),\n          data = d,\n          family = wiener(link_bs = \"identity\",\n                          link_ndt = \"identity\",\n                          link_bias = \"identity\"),\n          cores = parallel::detectCores(),\n          chains = 4,\n          backend = \"cmdstanr\")\n```\n:::\n\n\n:::\n\n:::\n\n## Diffusions Modell in der Forschung\n\nWeil mit dem Diffusionsmodell verschiedene Aspekte des Entscheidungsprozesses getrennt werden können, wird dieses Modell häufig in der Forschung verwendet. So können detailierte Einsichten gewonnen werden, wie das z.B. mit einfachen Hypothesentests möglich wäre. Hier ein paar Beispiele:\n\n- Untersuchung der kognitiven Eigenschaften bei ADHS [Review](https://psycnet.apa.org/doiLanding?doi=10.1037%2Fbul0000319)\n- Untersuchung des Entscheidungsverhaltens im Zusammenhang mit Abhängigkeit ([Tabak](https://pubmed.ncbi.nlm.nih.gov/36929415/), [Alkohol](file:///Users/dafitze/Downloads/dora_et_al_ECP_2023.pdf) und [Glücksspiel)](https://www.sciencedirect.com/science/article/pii/S0149763423000520)\n- Untersuchung des Entscheidungsverhaltens im Zusammenhang mit [Depression](https://pubmed.ncbi.nlm.nih.gov/35678933/), und [Angst](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2859713/).\n- Untersuchung von verändertem Entscheidungsverhalten aufgrund von strukturellen oder funktionalen Veränderungen des Gehirns z.B. bei [Parkinson](https://pubmed.ncbi.nlm.nih.gov/35069160/).\n",
    "supporting": [
      "ddm_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}